{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSHI7j-Q28j3"
   },
   "source": [
    "# Семинар 6: предобработка данных и функции потерь в линейной регрессии\n",
    "\n",
    "## Вступление\n",
    "Сегодня мы продолжим обсуждать предобработку данных, добавив к ней генерацию новых признаков. Потом обсудим различные функции потерь для линейной регрессии, визуально сравним их. Ну и закончим тем, чего все давно ждали: познакомимся подробнее с интерфейсами линейных моделей и методов отбора признаков в sklearn, обучим ряд линейных моделей.\n",
    "\n",
    "### План семинара\n",
    "1. Предоработка данных\n",
    "    - Заполнение пропусков\n",
    "    - Преобразование нечисловых признаков\n",
    "    - Масштабирование\n",
    "    - Генерация новых признаков\n",
    "2. Имплементация и визуализация функций потерь для регрессии\n",
    "    - MSE, RMSE, R2 score\n",
    "    - MAE\n",
    "    - Huber Loss\n",
    "    - Logarithmic Loss\n",
    "    - Quantile Loss\n",
    "3. Обучение линейных моделей и отбор признаков\n",
    "\n",
    "## 1. Предоработка данных\n",
    "Для демонстраций загрузим набор данных [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/Automobile). В данных присутствуют категориальные, целочисленные и вещественнозначные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:17.310820Z",
     "end_time": "2023-03-01T13:28:18.632809Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u30Ou_XY28j5",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:18.633845Z",
     "end_time": "2023-03-01T13:28:19.621631Z"
    }
   },
   "outputs": [],
   "source": [
    "X_raw = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\",\n",
    "    header=None,\n",
    "    na_values=[\"?\"],\n",
    ")\n",
    "\n",
    "y = X_raw[25]\n",
    "X_raw = X_raw.drop(25, axis=1)\n",
    "\n",
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Заполним пропуски средними и пустыми строками"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHXo8yny28j_",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:19.626525Z",
     "end_time": "2023-03-01T13:28:19.632940Z"
    }
   },
   "outputs": [],
   "source": [
    "# создаем маску, указывающую на столбцы с категориальными признаками\n",
    "cat_features_mask = (X_raw.dtypes == \"object\").values\n",
    "\n",
    "# для вещественнозначных признаков заполним пропуски средними\n",
    "X_real = X_raw[X_raw.columns[~cat_features_mask]]\n",
    "mis_replacer = SimpleImputer(strategy=\"mean\")\n",
    "X_no_mis_real = pd.DataFrame(\n",
    "    data=mis_replacer.fit_transform(X_real), columns=X_real.columns\n",
    ")\n",
    "\n",
    "# для категориальных — пустыми строками\n",
    "X_cat = X_raw[X_raw.columns[cat_features_mask]].fillna(\"\")\n",
    "X_no_mis = pd.concat([X_no_mis_real, X_cat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNoCS3EK28kR"
   },
   "source": [
    "#### Преобразуем нечисловые признаки при помощи one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "hLiNNMYz28kc",
    "outputId": "71635d35-f724-43d8-9244-cb83af917b0a",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:19.634185Z",
     "end_time": "2023-03-01T13:28:19.730659Z"
    }
   },
   "outputs": [],
   "source": [
    "X_dum = pd.get_dummies(X_no_mis, drop_first=True)\n",
    "print(f\"Data shape: {X_dum.shape}\")\n",
    "X_dum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaZ_SxAP28kf"
   },
   "source": [
    "#### Отмасштабируем признаки MinMaxScaler'ом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNymKr5D28kh",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:19.662833Z",
     "end_time": "2023-03-01T13:28:19.751117Z"
    }
   },
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "X_real_norm_np = normalizer.fit_transform(X_dum)\n",
    "X = pd.DataFrame(data=X_real_norm_np)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbwg7jRv28kn"
   },
   "source": [
    "#### Сгенерируем новые признаки\n",
    "Особенно важным моментом для линейной регрессии является нелинейное преобразование признаков. Это позволяет использовать линейную регрессию для моделирования нелинейных зависимостей.\n",
    "\n",
    "Наиболее популярны такие преобразования:\n",
    "- добавление полиномиальных признаков (`PolynomialFeatures` в sklearn)\n",
    "- взятие логарифма признака\n",
    "- взятие квадратного корня\n",
    "- применение тригонометрических функций\n",
    "\n",
    "Делать добавление признаков нужно с умом: большое количество полиномиальных и прочих новых признаков может сильно раздуть размер таблицы с данными, что может негативно сказаться на скорости и качестве моделирования.\n",
    "\n",
    "Небольшой пример. Посмотрев на наши данные, мы можем заметить, что зависимость целевой переменной от шестого признака скорее квадратичная, чем линейная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Bv0qZAP028kr",
    "outputId": "c1fbdef3-0154-4870-d258-1b46177dc96d",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:19.691057Z",
     "end_time": "2023-03-01T13:28:20.019803Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[6], y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "In7bi4a728ku",
    "outputId": "d01a472e-d0e9-446a-f011-2944ef6fdb65",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:19.871417Z",
     "end_time": "2023-03-01T13:28:20.046235Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[6] ** 2, y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LLqJaxF28kw"
   },
   "source": [
    "А для признака номер 13 линеаризовать зависимость получается с помощью функции $\\frac 1 {\\sqrt{x}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Ff2MqK_U28kx",
    "outputId": "ca370ede-de10-4c7c-f0cb-5fdf1a7717c9",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.043706Z",
     "end_time": "2023-03-01T13:28:20.212335Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[13], y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "6MhgQI3p28kz",
    "outputId": "444da03b-f69c-41f3-98d8-f96105777bc8",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.219174Z",
     "end_time": "2023-03-01T13:28:20.403012Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(1 / np.sqrt(X[13]), y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPqAUdTR28k1"
   },
   "source": [
    "## 2. Имплементация и визуализация функций потерь для регрессии\n",
    "\n",
    "Функционал качества в задачах обучения с учителем обычно задается в виде суммы по объектам выборки:\n",
    "$$Q(a) = \\frac 1 \\ell \\sum_{i=1}^\\ell L(y_i, a(x_i)),$$\n",
    "где $L(\\cdot, \\cdot)$ - функция потерь, задающая штраф за разницу между предсказанием и истинным значением целевого признака. Свойства функции потерь:\n",
    "* $L(y_i, a(x_i)) \\geqslant 0$;\n",
    "* $L(y_i, y_i) = 0$.\n",
    "\n",
    "Функционал качества должен в первую очередь отвечать требованиям заказчика, при этом математические свойства функции потерь могут быть неудобны для оптимизации.\n",
    "\n",
    "__Пример:__ если мы не различаем маленькие ошибки (между 0.01 и 0.1 нет особой разницы), но зато не хотим получать большие ошибки, можно использовать следующую функцию потерь:\n",
    "\n",
    "$$L(y_i, a(x_i)) = [| y_i - a(x_i) | < \\varepsilon],$$ $\\varepsilon$ — допустимая разница между предсказанием и фактом.\n",
    "\n",
    "### MSE, RMSE, R2 score\n",
    "Кроме требований заказчика, функционал качества должен учитывать математические особенности модели, например, устойчивость к шумовым объектам.\n",
    "\n",
    "В линейной регрессии Mean Squared Error: $L(y_i, a(x_i)) = (a(x_i) - y_i)^2$ не обладает этим свойством, потому что задает очень большие штрафы за большие отклонения от фактического значения.\n",
    "\n",
    "$$MSE (a, X, Y) = \\sum^L_{i=1}(a(x_i) - y_i)^2$$\n",
    "\n",
    "Рассмотрим это явление на примере. Выберем один признак, от которого целевой признак (имеющий индекс 15 в матрице X) зависит практически линейно. Добавим к выборке два объекта-выброса и посмотрим, как изменится оптимизированная на MSE прямая.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVmJjuUU28k7",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.406047Z",
     "end_time": "2023-03-01T13:28:20.408064Z"
    }
   },
   "outputs": [],
   "source": [
    "X_subset = X[[7, 15]].values\n",
    "X_subset_modified = np.vstack(\n",
    "    (X_subset, [[1, 90], [2, 50]])\n",
    ")  # добавление двух шумовых точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNZJOsJp28k9",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.413043Z",
     "end_time": "2023-03-01T13:28:20.414752Z"
    }
   },
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MSE(\n",
    "    X_subset: np.array, ax: matplotlib.axes._axes.Axes\n",
    ") -> None:\n",
    "    # визуализируем точки\n",
    "    ax.scatter(X_subset[:, 0], X_subset[:, 1])\n",
    "\n",
    "    # обучим линейную модель\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_subset[:, 0][:, np.newaxis], X_subset[:, 1])\n",
    "\n",
    "    # визуализируем прямую\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    line = lr.predict(grid[:, np.newaxis])\n",
    "    ax.plot(grid, line)\n",
    "    ax.set_ylim(-20, 100)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "EurNOGcA28k_",
    "outputId": "a0a4b098-838b-4f81-9796-b6fb5f1d80eb",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.419014Z",
     "end_time": "2023-03-01T13:28:20.750785Z"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax[0].set_title(\"MSE without outliers\")\n",
    "scatter_points_and_plot_line_MSE(X_subset, ax[0])\n",
    "ax[1].set_title(\"MSE with outliers\")\n",
    "scatter_points_and_plot_line_MSE(X_subset_modified, ax[1])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6JR5Gxq8ZcZ"
   },
   "source": [
    "**Задание.** Реализуйте функцию для подсчета MSE с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1mp3T5y844J",
    "outputId": "8bec51dd-6f89-4b1a-9653-9964ca0e4c34",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.752982Z",
     "end_time": "2023-03-01T13:28:20.756022Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE(y: np.array, y_pred: np.array) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "\n",
    "\n",
    "a = np.array([11, 20, 19, 17, 10])\n",
    "pred = np.array([12, 18, 19.5, 18, 9])\n",
    "mse = MSE(y=a, y_pred=pred)\n",
    "print(f\"Mean Square Error is: {mse}\")\n",
    "assert mse == 1.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoNn7V3VAxH7"
   },
   "source": [
    "Среднеквадратичная ошибка подходит для сравнения двух моделей или для контроля качества во время обучения. Из-за того, разница возводится в квадрат, сложно дать этому числу интерпретацию. Для лучшей интерпретации используется Root Mean Square Error (RMSE): её значение имеет те же масштабы, что и целевая переменная.\n",
    "\n",
    "$$RMSE (a, X, Y) = \\sqrt{MSE (a, X)} = \\sqrt{ \\sum^L_{i=1}(a(x_i) - y_i)^2}$$\n",
    "\n",
    "**Задание.** Реализуйте функцию для подсчета RMSE с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IowhU6p1Cj47",
    "outputId": "4c63cf61-4097-4488-f889-8a8c8eb777c6",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.760760Z",
     "end_time": "2023-03-01T13:28:20.764523Z"
    }
   },
   "outputs": [],
   "source": [
    "def RMSE(y: np.array, y_pred: np.array) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "\n",
    "\n",
    "rmse = RMSE(y=a, y_pred=pred)\n",
    "print(f\"Root Mean Square Error is: {rmse}\")\n",
    "assert rmse == 1.2041594578792296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3eqYonVJd8a"
   },
   "source": [
    "Коэффициент детерминации $R^2$ показывает долю дисперсии в целевой переменной, которая объяснена зависимыми переменными. $R^2$ можно интерпретировать как некоторого рода нормированное MSE.\n",
    "\n",
    "$$R^2(a, X, Y) = 1 - \\frac {\\sum^L_{i=1}(a(x_i) - y_i)^2}{\\sum^L_{i=1}(y_i - \\bar{y})^2}$$\n",
    "\n",
    "- Если $R^2 < 0$, значит наша модель даёт предсказание хуже константы в виде среднего значения целевой переменной, то есть абсолютно бесполезна с точки зрения MSE.\n",
    "- Если $R^2 = 0$, значит мы предсказываем не лучше и не хуже константы в виде среднего значения целевой переменной.\n",
    "- Если $0 < R^2 < 1$, значит модель работает лучше константного предсказания с точки зрения MSE.\n",
    "- Если $R^2 = 1$, значит ошибка MSE равна нулю. Это может произойти, например, при полном переобучении на тренировочной части выборки.\n",
    "\n",
    "**Задание.** Реализуйте функцию для подсчета $R^2$ с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KK3o7GozLjkV",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.763858Z",
     "end_time": "2023-03-01T13:28:20.768631Z"
    }
   },
   "outputs": [],
   "source": [
    "def R_squared(y: np.array, y_pred: np.array) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "\n",
    "\n",
    "r_squared = R_squared(y=a, y_pred=pred)\n",
    "print(f\"R2 score is: {r_squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa7c8WRk28lC"
   },
   "source": [
    "### MAE\n",
    "Из-за того, что в MSE мы учитываем квадрат отклонения, шумовые объекты могут сильно изменить наклон прямой. Поэтому в качестве альтернативы MSE можно использовать Mean Absolute Error: $L(y_i, a(x_i)) = |a(x_i) - y_i|$.\n",
    "\n",
    "$$MAE(a, X, Y) = \\frac {1}{L} \\sum^L_{i=1}|a(x_i) - y_i|$$\n",
    "\n",
    "Теперь обучим регрессию, оптимизируя MAE. В `sklearn` такая регрессия не реализована, но можно использовать модуль `statsmodels`. Более формально, необходимая модель может быть получена с помощью обучения квантильной регрессии с параметром `q=0.5`.\n",
    "\n",
    "**Задание.** Реализуйте функцию для подсчета MAE с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eo-0TW82DzPw",
    "outputId": "f4e36fd7-9184-4ebb-e7f6-79e48d5c9124",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.771470Z",
     "end_time": "2023-03-01T13:28:20.874294Z"
    }
   },
   "outputs": [],
   "source": [
    "def MAE(y: np.array, y_pred: np.array) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "\n",
    "\n",
    "mae = MAE(y=a, y_pred=pred)\n",
    "print(f\"Mean Absolute Error is: {mae}\")\n",
    "assert mae == 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/statsmodels/statsmodels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.776113Z",
     "end_time": "2023-03-01T13:28:20.874731Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PL2zqH8x28lD",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.780886Z",
     "end_time": "2023-03-01T13:28:20.890593Z"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFTTYeqY28lF",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.882087Z",
     "end_time": "2023-03-01T13:28:20.891333Z"
    }
   },
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MAE(\n",
    "    X_subset: np.array, ax: matplotlib.axes._axes.Axes\n",
    ") -> None:\n",
    "    # визуализируем точки\n",
    "    ax.scatter(X_subset[:, 0], X_subset[:, 1])\n",
    "\n",
    "    # задаем зависимость переменной f15 от переменной f7 и передаем данные\n",
    "    mod = smf.quantreg(\"f15 ~ f7\", pd.DataFrame(data=X_subset, columns=[\"f7\", \"f15\"]))\n",
    "    res = mod.fit(q=0.5)\n",
    "\n",
    "    # визуализируем прямую\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    line = grid * res.params[\"f7\"] + res.params[\"Intercept\"]\n",
    "    ax.plot(grid, line)\n",
    "    ax.set_ylim(-20, 100)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ie_4TNdc28lH",
    "outputId": "85bcab8b-0876-4f52-98a7-87dc18beecdd",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:20.890976Z",
     "end_time": "2023-03-01T13:28:21.225984Z"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax[0].set_title(\"MAE without outliers\")\n",
    "scatter_points_and_plot_line_MAE(X_subset, ax[0])\n",
    "ax[1].set_title(\"MAE with outliers\")\n",
    "scatter_points_and_plot_line_MAE(X_subset_modified, ax[1])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWlsyGfu28lK"
   },
   "source": [
    "Прямая практически не изменила направление из-за выбросов! Попробуем добавить больше шумовых объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdDGJBER28lM",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:21.227425Z",
     "end_time": "2023-03-01T13:28:21.229916Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "X_subset_modified_twice = np.vstack(\n",
    "    (X_subset_modified, np.random.randint(5, size=60).reshape(-1, 2) * [1, 30])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "McWJOOlN28lO",
    "outputId": "c44d54b7-7cda-4650-cf53-257573a82815",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:21.232487Z",
     "end_time": "2023-03-01T13:28:21.576038Z"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax[0].set_title(\"MAE without outliers\")\n",
    "scatter_points_and_plot_line_MAE(X_subset_modified_twice, ax[0])\n",
    "ax[1].set_title(\"MAE with outliers\")\n",
    "scatter_points_and_plot_line_MAE(X_subset_modified_twice, ax[1])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCq7zu_K28lQ"
   },
   "source": [
    "Под таким количеством выбросов, изменилась даже регрессия над MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PMB5CGj28lR"
   },
   "source": [
    "#### Оптимальные константы для MSE и MAE\n",
    "\n",
    "Допустим алгоритм возвращает константное предсказание: $a(x) = C, C \\in R$. В качестве примера такого алгоритма можно представить предсказание прибыли в январе константой, равной средней прибыли за январь всех предыдущих лет работы.\n",
    "\n",
    "**Задание.** Найдите $C$, минимизирующий среднеквадратичную ошибку.\n",
    "\n",
    "**Решение.** Нам необходимо найти константу C, минимизирующую функцию $\\frac{1}{n} \\sum_{i}^{n} (C - y_i)^2$. Для этого возьмём производную этой функции и приравняем её к нулю. Константы сразу можно сократить: $\\sum_{i}^{n} (C - y_i) = 0$. Преобразуем это выражение и выпишем ответ: $C = \\frac{\\sum_{i}^{n} y_i}{n}$. То есть оптимальная константа — среднее значение целевой переменной.\n",
    "\n",
    "**Задание.** Найдите $C$, минимизирующий среднюю абсолютную ошибку.\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMkNLdXE28lS"
   },
   "source": [
    "### Huber Loss\n",
    "Иногда используют \"гибрид\" MAE и MSE, который, как и MAE, устойчив к шумовым объектам, и, как и MSE, мало штрафует малые отклонения от фактического значения целевого признака. Этот гибрид называется Huber Loss:\n",
    "\n",
    "$$L_i(y_i, a(x_i)) = \\phi_\\varepsilon(a(x_i) - y_i)$$\n",
    "$$\\phi_\\varepsilon(z) = \\begin{cases} \\frac 1 2 z^2, - \\varepsilon < z < \\varepsilon, \\\\\\varepsilon (|z| - \\frac 1 2 \\varepsilon), иначе \\\\ \\end{cases}$$\n",
    "\n",
    "Можно проверить, что у этой функции существует непрерывная первая производная во всех точках.\n",
    "\n",
    "Оптимизация Huber Loss реализована в sklearn.\n",
    "\n",
    "**Задание.** Реализуйте функцию для подсчета Huber Loss с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyTaEVslFGb5",
    "outputId": "9223c84d-8e2a-438e-c0bd-35aa797dd8e7",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:21.579751Z",
     "end_time": "2023-03-01T13:28:21.582585Z"
    }
   },
   "outputs": [],
   "source": [
    "def Huber(y: np.array, y_pred: np.array, eps: float = 1) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "\n",
    "\n",
    "huber = Huber(y=a, y_pred=pred, eps=1)\n",
    "print(\"Huber Loss is:\", huber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00WIecdEGqE7"
   },
   "source": [
    "### Mean Squared Logarithmic Error (MSLE)\n",
    "\n",
    "Эта функция потерь применяется в случаях, когда лучше получать заниженные прогнозы, нежели завышенные. Ещё она полезна, когда нас больше интересует правильно попасть в порядок целевой переменной, чем в её конкретное значение. Обратите внимание, что из-за присутствия логарифма в формуле **целевая переменная должна быть неотрицательной**. Единицу добавляем, чтобы случайно не получить логарифм нуля.\n",
    "\n",
    "$$L_i(a, X_i, Y_i) = (\\log(a(x_i)+1) - \\log(y_i+1))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDbvxTRyHyRB"
   },
   "source": [
    "**Задание.** Реализуйте функцию для подсчета MSLE с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzpzqKvLINLo",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:21.584552Z",
     "end_time": "2023-03-01T13:28:21.587281Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSLE(y: np.array, y_pred: np.array) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "\n",
    "\n",
    "msle = MSLE(y=a, y_pred=pred)\n",
    "print(f\"Mean Squared Logarifmic Error is: {msle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5Yy3Ze228lV"
   },
   "source": [
    "### Quantile Loss\n",
    "В некоторых задачах штраф за ошибку зависит не только от величины абсолютного отклонения от фактического значения, но и от знака этого отклонения. Например, лучше предсказать спрос больше, чем будет по факту, чем меньше, потому что во втором случае будет потеряна прибыль. В этом случае используется квантильная регрессия со следующей функцией потерь:\n",
    "$$L_i(y_i, a(x_i)) = \\rho_\\tau(y_i - x_i^T w),$$\n",
    "$$\\rho_\\tau(z) = \\begin{cases} \\tau z, \\quad z > 0, \\\\ (\\tau - 1) z, \\quad z \\leqslant 0 \\end{cases}$$\n",
    "Параметр $\\tau \\in (0, 1)$ влияет на то, насколько различаются штрафы за положительную и отрицательную разницу.\n",
    "\n",
    "Изобразим график квантильной функции потерь вместе с некоторыми другими рассмотренными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "LZvF9yTL28lW",
    "outputId": "124dc493-7f6c-486d-9adf-2379c3d2ef6e",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:21.592897Z",
     "end_time": "2023-03-01T13:28:22.038131Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = np.linspace(-3, 3, 100)\n",
    "quantile_tau = 0.2\n",
    "mse_loss = grid**2\n",
    "rmse_loss = np.sqrt(mse_loss)\n",
    "mae_loss = np.abs(grid)\n",
    "huber_loss = (\n",
    "    0.5 * mse_loss * (grid >= -1) * (grid <= 1)\n",
    "    + (mae_loss - 0.5) * (grid < -1)\n",
    "    + (mae_loss - 0.5) * (grid > 1)\n",
    ")\n",
    "quantile_loss = quantile_tau * grid * (grid > 0) + (quantile_tau - 1) * grid * (\n",
    "    grid <= 0\n",
    ")\n",
    "plt.plot(grid, mae_loss, label=\"Absolute Loss\")\n",
    "plt.plot(grid, mse_loss, label=\"Quadratic Loss\")\n",
    "plt.plot(grid, rmse_loss, label=\"Root Quadratic Loss\")\n",
    "plt.plot(grid, huber_loss, label=\"Huber Loss\")\n",
    "plt.plot(grid, quantile_loss, label=\"Quantile Loss\")\n",
    "plt.xlabel(\"$y_i - a(x_i)$\", fontsize=14)\n",
    "plt.ylabel(\"$L(y_i, a(x_i))$\", fontsize=14)\n",
    "plt.title(\"Loss functions comparison\", fontsize=18)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2jmXcciOl-K"
   },
   "source": [
    "## 3. Обучение линейных моделей и отбор признаков\n",
    "\n",
    "Мы поработаем с данными о сообществах в США. Будем предсказывать количество насильственных преступлений относительно численности населения.\n",
    "\n",
    "[Описание датасета](http://archive.ics.uci.edu/ml/datasets/communities+and+crime)\n",
    "[Датасет на кэггле](https://www.kaggle.com/kkanda/communities%20and%20crime%20unnormalized%20data%20set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3lmXNVFOx0G",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.037079Z",
     "end_time": "2023-03-01T13:28:22.042689Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRft8CJyO1z8",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.046800Z",
     "end_time": "2023-03-01T13:28:22.134764Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"crimedata.csv\", na_values=[\"?\"])\n",
    "\n",
    "# оставим лишь нужные колонки\n",
    "requiredColumns = [5, 6] + list(range(11, 26)) + list(range(32, 103)) + [145]\n",
    "data = data[data.columns[requiredColumns]]\n",
    "\n",
    "# некоторые значения целевой переменной пропущены\n",
    "X = data.loc[data[\"ViolentCrimesPerPop\"].notnull(), :].drop(\n",
    "    \"ViolentCrimesPerPop\", axis=1\n",
    ")\n",
    "y = data[\"ViolentCrimesPerPop\"][X.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCxXAdVtOiw4"
   },
   "source": [
    "### Baseline\n",
    "Обучим линейную регрессию и выведем качество по метрике MSE на обучающей и тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntYfZTzkQRAC",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.085999Z",
     "end_time": "2023-03-01T13:28:22.135053Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, lr.predict(X_train))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lr.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd44Omp9TtcU"
   },
   "source": [
    "Популярным решением для регрессионных моделей является **регуляризация**.\n",
    "\n",
    "Во время оптимизации линейной регрессии, веса при переменных могут получиться большими в абсолютных значениях. Это не очень хорошо, поскольку классификатор будет чувствителен к крайне маленьким изменениям в признаках объекта, а значит, переобучен. Для решения проблемы к функционалу ошибки добавляют регуляризатор, который \"штрафует\" модель за слишком большую норму вектора весов:\n",
    "\n",
    "$$Q\\alpha(w) = Q(w) + \\alpha R(w)$$ \n",
    "\n",
    "где $R(w)$ — регуляризатор\n",
    "\n",
    "Наиболее распространенными являются L1 и L2 регуляризаторы:\n",
    "$$L1: R(w) = ||w||_1 = \\sum^d_i w_i^2$$\n",
    "\n",
    "$$L2: R(w) = ||w||_2 = \\sum^d_i |w_i|$$\n",
    "\n",
    "Давайте применим каждый из них к нашей задаче и посмотрим на изменение в результатах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RT8QZldbPqFr",
    "outputId": "126eb557-1c3d-4bdb-fe05-a4eb0adc1d76",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.109115Z",
     "end_time": "2023-03-01T13:28:22.246669Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(5.0).fit(X_train, y_train)\n",
    "print(\"Lasso\")\n",
    "print(f\"Train: {mean_squared_error(y_train, lasso.predict(X_train))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lasso.predict(X_test))}\")\n",
    "\n",
    "ridge = Ridge(5.0).fit(X_train, y_train)\n",
    "print(\"\\nRidge\")\n",
    "print(f\"Train: {mean_squared_error(y_train, ridge.predict(X_train))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, ridge.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzcwQ0T5QkRJ"
   },
   "source": [
    "### Scaling\n",
    "Попробуем MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zedtNiBBQhOl",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.224569Z",
     "end_time": "2023-03-01T13:28:22.246880Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(data=sc.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(data=sc.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrldySniQ6jR"
   },
   "source": [
    "**Задание.** Напишите код обучения линейной регрессии на масштабированных признаках и выведите ошибку на обучающей и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyoESXkkRQA1",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.239547Z",
     "end_time": "2023-03-01T13:28:22.327050Z"
    }
   },
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkbwYrUdRSYR"
   },
   "source": [
    "**Задание:** проделайте аналогичную работу, добавив Ridge регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDELVx5FRh1F",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.257103Z",
     "end_time": "2023-03-01T13:28:22.328526Z"
    }
   },
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK7GsUVORnbG"
   },
   "source": [
    "### Отбор признаков на основе дисперсии\n",
    "\n",
    "Полезны ли признаки, имеющие высокую дисперсию? А низкую?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDlYyvBsRnwb",
    "outputId": "99a5078b-8d5c-4079-b130-c096ac8c41d4",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.275897Z",
     "end_time": "2023-03-01T13:28:22.329015Z"
    }
   },
   "outputs": [],
   "source": [
    "features_variance = X_train_scaled.var().sort_values(ascending=False)\n",
    "features_variance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qW04UvAbRyhG"
   },
   "source": [
    "Попробуем удалить признаки с самой низкой дисперсией и посмотреть, как изменится качество. В sklearn есть специальный инструмент для такого наивного отбора признаков. Стоит ли нормализовать перед этим признаки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.287871Z",
     "end_time": "2023-03-01T13:28:22.329160Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StGlZfbeRsec",
    "outputId": "ef18c63f-14c6-4d84-98f7-ccc92e707dbe",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.306165Z",
     "end_time": "2023-03-01T13:28:22.329418Z"
    }
   },
   "outputs": [],
   "source": [
    "# можно убрать все признаки, дисперсия которых меньше заданного значения\n",
    "vs_transformer = VarianceThreshold(0.01)\n",
    "\n",
    "X_train_var = pd.DataFrame(\n",
    "    data=vs_transformer.fit_transform(X_train_scaled),\n",
    "    columns=X_train_scaled.columns[vs_transformer.get_support()],\n",
    ")\n",
    "X_test_var = pd.DataFrame(\n",
    "    data=vs_transformer.transform(X_test_scaled),\n",
    "    columns=X_test_scaled.columns[vs_transformer.get_support()],\n",
    ")\n",
    "\n",
    "X_train_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z60-yCrwR2rG",
    "outputId": "b4294aec-3712-41f5-8170-f924cfcd155b",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.320589Z",
     "end_time": "2023-03-01T13:28:22.474516Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_var, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, lr.predict(X_train_var))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lr.predict(X_test_var))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXlTH65eR5hs",
    "outputId": "5c6ce1a9-aa30-4b95-86fd-0ecda5f9791e",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.351687Z",
     "end_time": "2023-03-01T13:28:22.500978Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_var, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, ridge.predict(X_train_var))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, ridge.predict(X_test_var))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-tIhMytR9KO"
   },
   "source": [
    "### Отбор признаков на основе корреляции с целевой переменной\n",
    "Можно выбрать k признаков, которые дают наиболее высокие значения корреляции с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.361419Z",
     "end_time": "2023-03-01T13:28:22.501271Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxgWrpvVR7_H",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.364570Z",
     "end_time": "2023-03-01T13:28:22.501897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Выбираем 15 лучших признаков\n",
    "sb = SelectKBest(f_regression, k=15)\n",
    "\n",
    "X_train_kbest = pd.DataFrame(\n",
    "    data=sb.fit_transform(X_train_var, y_train),\n",
    "    columns=X_train_var.columns[sb.get_support()],\n",
    ")\n",
    "X_test_kbest = pd.DataFrame(\n",
    "    data=sb.transform(X_test_var), columns=X_test_var.columns[sb.get_support()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05_0s6Y0SPYp",
    "outputId": "4d2beea0-bc84-42ad-f239-3002fb223ef9",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.382292Z",
     "end_time": "2023-03-01T13:28:22.502236Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_kbest, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, lr.predict(X_train_kbest))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lr.predict(X_test_kbest))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brBAuwBHSSXA",
    "outputId": "3ea8e8b3-4be0-4071-9a42-50453af4d5bc",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.406423Z",
     "end_time": "2023-03-01T13:28:22.502423Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_kbest, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, ridge.predict(X_train_kbest))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, ridge.predict(X_test_kbest))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1oWr6MASWck"
   },
   "source": [
    "А можно выбрать самые значимые признаки с точки зрения регрессии с $L_1$-регуляризацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.415667Z",
     "end_time": "2023-03-01T13:28:22.502549Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R7rsWRvSVFA",
    "outputId": "be80b01d-4ccb-4231-8f99-c36459d30215",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.423681Z",
     "end_time": "2023-03-01T13:28:22.502898Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(5.0)\n",
    "l1_select = SelectFromModel(lasso)\n",
    "\n",
    "X_train_l1 = pd.DataFrame(\n",
    "    data=l1_select.fit_transform(X_train_var, y_train),\n",
    "    columns=X_train_var.columns[l1_select.get_support()],\n",
    ")\n",
    "X_test_l1 = pd.DataFrame(\n",
    "    data=l1_select.transform(X_test_var),\n",
    "    columns=X_test_var.columns[l1_select.get_support()],\n",
    ")\n",
    "\n",
    "X_train_l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VO2rVJfSikj",
    "outputId": "c2194e3b-8341-40cf-c0cd-a9616df38c72",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.435381Z",
     "end_time": "2023-03-01T13:28:22.503130Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_l1, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, lr.predict(X_train_l1))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lr.predict(X_test_l1))}\")\n",
    "\n",
    "ridge = Ridge(5.0).fit(X_train_l1, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, ridge.predict(X_train_l1))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, ridge.predict(X_test_l1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlvrsWnsSqJ2"
   },
   "source": [
    "### Зададим все преобразования, отбор признаков и обучение при помощи Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6SHSnsUSpJU",
    "outputId": "ae41e7cd-bcdd-43b0-844e-b830c2b8821a",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.456144Z",
     "end_time": "2023-03-01T13:28:22.504394Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"variance\", VarianceThreshold(0.01)),\n",
    "        (\"selection\", SelectFromModel(Lasso(5.0))),\n",
    "        (\"regressor\", Ridge(5.0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R84AM0WISw1i",
    "outputId": "7ab81bbe-a396-4eed-bb17-01db96062e6e",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.485230Z",
     "end_time": "2023-03-01T13:28:22.629900Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Train: {mean_squared_error(y_train, pipe.predict(X_train))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, pipe.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN1m9tlWS2zh"
   },
   "source": [
    "Можно даже перебрать гиперпараметры с помощью `GridSearch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fqn1f7qS2Kt",
    "outputId": "b07efc95-76ec-4699-dda9-9b80a2293f9d",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.503101Z",
     "end_time": "2023-03-01T13:28:22.657496Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4m5LRWZgS_3e",
    "outputId": "7772273e-c44b-4298-e513-abd490a91ac4",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:22.507455Z",
     "end_time": "2023-03-01T13:28:55.223430Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"variance__threshold\": [0.005, 0.0075, 0.009, 0.01, 0.011, 0.012],\n",
    "    \"selection__estimator__alpha\": [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "    \"regressor__alpha\": [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G98XFUynTGJV",
    "outputId": "052f7b76-a35a-4c9d-83f2-19b69f9b1267",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:55.210272Z",
     "end_time": "2023-03-01T13:28:55.224075Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_best = grid_search.best_estimator_\n",
    "pipe_best.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Uhgfp_WTJvD",
    "outputId": "4206a94b-01cb-4429-ed67-6f57ed016262",
    "ExecuteTime": {
     "start_time": "2023-03-01T13:28:55.225228Z",
     "end_time": "2023-03-01T13:28:55.336199Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_best.fit(X_train, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, pipe_best.predict(X_train))}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, pipe_best.predict(X_test))}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "sem06_linreg_unsolved.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
